{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# from pptoolbox import cross_group_predict\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    # 'full': {},\n",
    "    'nondeo': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing nondeo dataset\n",
      "X_train: (2178, 191), y_train: (2178, 18)\n",
      "X_test: (533, 191), y_test: (533, 18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f'Processing {dataset} dataset')\n",
    "\n",
    "    save_dir = f\"../data/cargill/{dataset}\"\n",
    "\n",
    "    X_train = pd.read_csv(f'{save_dir}/Xtrain.csv', index_col=0)\n",
    "    X_test = pd.read_csv(f'{save_dir}/Xtest.csv', index_col=0)\n",
    "    y_train = pd.read_csv(f'{save_dir}/ytrain.csv', index_col=0)\n",
    "    y_test = pd.read_csv(f'{save_dir}/ytest.csv', index_col=0)\n",
    "\n",
    "    datasets[dataset]['X_train'] = X_train\n",
    "    datasets[dataset]['X_test'] = X_test\n",
    "    datasets[dataset]['y_train'] = y_train\n",
    "    datasets[dataset]['y_test'] = y_test\n",
    "\n",
    "    print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n",
    "    print(f'X_test: {X_test.shape}, y_test: {y_test.shape}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['specimen_id', 'lot_name', 'date_scanned', 'Acetic', 'Ash',\n",
       "       'Astringent', 'Earthy', 'Fishy', 'Musty',\n",
       "       'Oxidized (Old Butter-Stale-Cardboard)', 'Painty (Solvent-Chemical)',\n",
       "       'Petroleum (Motor Oil-Rubber)', 'Putrid', 'Sensory Result', 'Smoky',\n",
       "       'Sour', 'Sensory Value', 'scan_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['specimen_id',\n",
       " 'lot_name',\n",
       " 'date_scanned',\n",
       " 'Acetic',\n",
       " 'Ash',\n",
       " 'Astringent',\n",
       " 'Earthy',\n",
       " 'Fishy',\n",
       " 'Musty',\n",
       " 'Oxidized (Old Butter-Stale-Cardboard)',\n",
       " 'Painty (Solvent-Chemical)',\n",
       " 'Petroleum (Motor Oil-Rubber)',\n",
       " 'Putrid',\n",
       " 'Sensory Result',\n",
       " 'Smoky',\n",
       " 'Sour',\n",
       " 'Sensory Value',\n",
       " 'scan_month']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params = list(y_test.columns)\n",
    "all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_train = [\n",
    "    'Acetic',\n",
    "    # 'Ash',\n",
    "    # 'Astringent',\n",
    "    # 'Bitter',\n",
    "    # 'Brown Fruit',\n",
    "    # 'Cacao (Chocolate)',\n",
    "    # 'Carbon',\n",
    "    # 'Deodorization Level',\n",
    "    # 'Earthy',\n",
    "    # 'Fishy',\n",
    "    # 'Heated Fat (Oil)',\n",
    "    # 'Musty',\n",
    "    # 'Oxidized (Old Butter-Stale-Cardboard)',\n",
    "    # 'Painty (Solvent-Chemical)',\n",
    "    # 'Petroleum (Motor Oil-Rubber)',\n",
    "    # 'Putrid',\n",
    "    # 'Sensory Result',\n",
    "    # 'Smoky',\n",
    "    # 'Sour',\n",
    "    # 'Straw (Hay)',\n",
    "    # 'Sensory Value'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acetic']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_params = set(params_to_train)\n",
    "remaining_params = list(set(remaining_params) - set(['Deodorization Level', 'Sensory Value']))\n",
    "remaining_params.sort()\n",
    "remaining_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from configs import (\n",
    "    STORAGE_URL,\n",
    ")\n",
    "\n",
    "from trainer import BaseClassifyTrainerV4,MultiObjClassifyTrainerV4\n",
    "from objective import DefaultClassifyV4, CustomObjectiveImbaClassify, MultiObjectiveImbaClassify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing nondeo dataset\n",
      "Training model for Acetic\n",
      "Model does not exist, training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/14 13:56:15 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2024-05-18; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'pptoolbox'}\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "\n",
    "    print(f'Processing {dataset} dataset')\n",
    "    X_train = datasets[dataset]['X_train']\n",
    "    y_train = datasets[dataset]['y_train']\n",
    "    X_test = datasets[dataset]['X_test']\n",
    "    y_test = datasets[dataset]['y_test']\n",
    "\n",
    "    for i, param in enumerate(remaining_params):\n",
    "\n",
    "        print(f'Training model for {param}')\n",
    "        \n",
    "        output_dir = Path(f\"../models/imba_constrained/{dataset}/{param}\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # check if model exists\n",
    "        if (output_dir / \"trainer.pkl\").exists():\n",
    "            print(\"Model exists, skipping training\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Model does not exist, training\")\n",
    "\n",
    "        selected_y_train = y_train[param]\n",
    "        selected_y_test = y_test[param]\n",
    "\n",
    "        #check if encoder exists\n",
    "        if (output_dir / \"encoder.pkl\").exists():\n",
    "            encoder = pkl.load(open(output_dir / \"encoder.pkl\", \"rb\"))\n",
    "            selected_y_train_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_train),\n",
    "                index = selected_y_train.index\n",
    "            )\n",
    "            selected_y_test_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_test),\n",
    "                index = selected_y_test.index\n",
    "            )\n",
    "        else:\n",
    "            encoder = LabelEncoder()\n",
    "            selected_y_train_encoded = pd.Series(\n",
    "                encoder.fit_transform(selected_y_train),\n",
    "                index = selected_y_train.index\n",
    "            )\n",
    "            selected_y_test_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_test),\n",
    "                index = selected_y_test.index\n",
    "            )\n",
    "\n",
    "            pkl.dump(encoder, open(output_dir / \"encoder.pkl\", \"wb\"))\n",
    "\n",
    "        MODULE_NAME = \"Classify\"\n",
    "        PROJECT_CODE = \"X24-028\"\n",
    "        MLFLOW_EXPERIMENT_NAME = f\"{MODULE_NAME}_{PROJECT_CODE}_{dataset}_{param}_multi_imba\"\n",
    "        OPTUNA_STUDY_NAME = f\"{MLFLOW_EXPERIMENT_NAME}_RUN-2\"\n",
    "        SEED = 42\n",
    "        N_STARTUP_TRIALS = 150\n",
    "        N_TOTAL_TRIALS = 400\n",
    "\n",
    "        sampler = TPESampler(seed=SEED, \n",
    "                            n_startup_trials=N_STARTUP_TRIALS, \n",
    "                            multivariate=True,\n",
    "                            warn_independent_sampling=False)\n",
    "        \n",
    "        objective = MultiObjectiveImbaClassify(\n",
    "            X_train = X_train,\n",
    "            y_train = selected_y_train_encoded,\n",
    "            X_test = X_test,\n",
    "            y_test = selected_y_test_encoded,\n",
    "\n",
    "        )\n",
    "        directions = [\"maximize\",\"maximize\"] # depends on your objective\n",
    "        metric_names = [\"minority_recall\", \"balanced_accuracy\"]\n",
    "\n",
    "        classify_trainer = MultiObjClassifyTrainerV4(\n",
    "            mlflow_experiment_name = MLFLOW_EXPERIMENT_NAME,\n",
    "            optuna_study_name = OPTUNA_STUDY_NAME,\n",
    "            optuna_storage_url = STORAGE_URL,\n",
    "            sampler = sampler,\n",
    "            n_total_trials = N_TOTAL_TRIALS,\n",
    "            objective = objective,\n",
    "            direction = directions,\n",
    "            metric_name = metric_names,\n",
    "            seed = SEED,\n",
    "            additional_tags = {f'metric_{i+1}': metric_names[i] for i in range(len(metric_names))},\n",
    "            enable_checkpointing=True,  # Enable the new feature\n",
    "            sampler_checkpoint_path=None,\n",
    "            encoder = encoder,\n",
    "        )\n",
    "\n",
    "        classify_trainer.run(save_best_model=True)\n",
    "\n",
    "        # pkl.dump(best_model, open(output_dir / \"trainer.pkl\", \"wb\"))\n",
    "        # pkl.dump(chosen_pipeline, open(output_dir / \"origin_model_prediction.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=177, state=TrialState.COMPLETE, values=[0.8658536585365854, 0.7111876988335101], datetime_start=datetime.datetime(2025, 4, 9, 21, 12, 17, 224706), datetime_complete=datetime.datetime(2025, 4, 9, 21, 13, 6, 945042), params={'mask': 0, 'preprocessor': 'SNV-SG', 'window': 11, 'deriv': 1, 'polyorder': 3, 'model': 'SVC(RBF)', 'C': 1.8335503342186157, 'gamma': 0.9644095683465055, 'sampler_method': 'Under', 'sampler_Under': 'ClusterCentroids', 'dim_red': True, 'dim_red_method': 'umap', 'dim_red__n_components': 5, 'dim_red__n_neighbors': 19}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'mask': CategoricalDistribution(choices=(0, 1, 2)), 'preprocessor': CategoricalDistribution(choices=('SNV', 'SG', 'SNV-SG')), 'window': IntDistribution(high=29, log=False, low=5, step=2), 'deriv': IntDistribution(high=2, log=False, low=1, step=1), 'polyorder': IntDistribution(high=3, log=False, low=2, step=1), 'model': CategoricalDistribution(choices=('DecisionTree', 'ExtraTrees', 'GaussianNB', 'GradientBoost', 'KNN', 'LDA', 'LogisticRegression', 'QDA', 'RandomForest', 'SGD', 'SVC(RBF)', 'SVC(Poly)', 'SVC(Sigmoid)')), 'C': FloatDistribution(high=1000.0, log=True, low=0.001, step=None), 'gamma': FloatDistribution(high=100.0, log=True, low=0.001, step=None), 'sampler_method': CategoricalDistribution(choices=(None, 'Under', 'Over', 'Combined')), 'sampler_Under': CategoricalDistribution(choices=('ClusterCentroids', 'RandomUnderSampler', 'TomekLinks')), 'dim_red': CategoricalDistribution(choices=(False, True)), 'dim_red_method': CategoricalDistribution(choices=('pca', 'umap')), 'dim_red__n_components': IntDistribution(high=24, log=False, low=2, step=1), 'dim_red__n_neighbors': IntDistribution(high=40, log=False, low=15, step=1)}, trial_id=6265, value=None),\n",
       " FrozenTrial(number=261, state=TrialState.COMPLETE, values=[0.8414634146341463, 0.7250795334040296], datetime_start=datetime.datetime(2025, 4, 9, 23, 6, 54, 805811), datetime_complete=datetime.datetime(2025, 4, 9, 23, 7, 44, 375250), params={'mask': 0, 'preprocessor': 'SNV-SG', 'window': 9, 'deriv': 1, 'polyorder': 3, 'model': 'SVC(RBF)', 'C': 1.5040755926593568, 'gamma': 0.035052012217756216, 'sampler_method': 'Under', 'sampler_Under': 'ClusterCentroids', 'dim_red': True, 'dim_red_method': 'umap', 'dim_red__n_components': 10, 'dim_red__n_neighbors': 18}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'mask': CategoricalDistribution(choices=(0, 1, 2)), 'preprocessor': CategoricalDistribution(choices=('SNV', 'SG', 'SNV-SG')), 'window': IntDistribution(high=29, log=False, low=5, step=2), 'deriv': IntDistribution(high=2, log=False, low=1, step=1), 'polyorder': IntDistribution(high=3, log=False, low=2, step=1), 'model': CategoricalDistribution(choices=('DecisionTree', 'ExtraTrees', 'GaussianNB', 'GradientBoost', 'KNN', 'LDA', 'LogisticRegression', 'QDA', 'RandomForest', 'SGD', 'SVC(RBF)', 'SVC(Poly)', 'SVC(Sigmoid)')), 'C': FloatDistribution(high=1000.0, log=True, low=0.001, step=None), 'gamma': FloatDistribution(high=100.0, log=True, low=0.001, step=None), 'sampler_method': CategoricalDistribution(choices=(None, 'Under', 'Over', 'Combined')), 'sampler_Under': CategoricalDistribution(choices=('ClusterCentroids', 'RandomUnderSampler', 'TomekLinks')), 'dim_red': CategoricalDistribution(choices=(False, True)), 'dim_red_method': CategoricalDistribution(choices=('pca', 'umap')), 'dim_red__n_components': IntDistribution(high=24, log=False, low=2, step=1), 'dim_red__n_neighbors': IntDistribution(high=40, log=False, low=15, step=1)}, trial_id=6349, value=None)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_trainer.get_study().best_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.711188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.725080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.865854  0.711188\n",
       "1  0.841463  0.725080"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trials = classify_trainer.get_study().best_trials\n",
    "results = np.array([trial.values for trial in best_trials])\n",
    "results = pd.DataFrame(results).sort_values([0, 1], ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mask': 0,\n",
       " 'preprocessor': 'SNV-SG',\n",
       " 'window': 9,\n",
       " 'deriv': 1,\n",
       " 'polyorder': 3,\n",
       " 'model': 'SVC(RBF)',\n",
       " 'C': 1.5040755926593568,\n",
       " 'gamma': 0.035052012217756216,\n",
       " 'sampler_method': 'Under',\n",
       " 'sampler_Under': 'ClusterCentroids',\n",
       " 'dim_red': True,\n",
       " 'dim_red_method': 'umap',\n",
       " 'dim_red__n_components': 10,\n",
       " 'dim_red__n_neighbors': 18}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = best_trials[1].params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/10 21:48:22 WARNING mlflow.utils.requirements_utils: The following packages were not found in the public PyPI package index as of 2024-05-18; if these packages are not present in the public PyPI index, you must install them manually before loading your model: {'pptoolbox'}\n"
     ]
    }
   ],
   "source": [
    "classify_trainer.save_best_model(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "\n",
    "    print(f'Processing {dataset} dataset')\n",
    "    X_train = datasets[dataset]['X_train']\n",
    "    y_train = datasets[dataset]['y_train']\n",
    "    X_test = datasets[dataset]['X_test']\n",
    "    y_test = datasets[dataset]['y_test']\n",
    "\n",
    "    for i, param in enumerate(remaining_params):\n",
    "\n",
    "        print(f'Training model for {param}')\n",
    "        \n",
    "        output_dir = Path(f\"../models/imba_constrained/{dataset}/{param}\")\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # check if model exists\n",
    "        if (output_dir / \"trainer.pkl\").exists():\n",
    "            print(\"Model exists, skipping training\")\n",
    "            continue\n",
    "        else:\n",
    "            print(\"Model does not exist, training\")\n",
    "\n",
    "        selected_y_train = y_train[param]\n",
    "        selected_y_test = y_test[param]\n",
    "\n",
    "        #check if encoder exists\n",
    "        if (output_dir / \"encoder.pkl\").exists():\n",
    "            encoder = pkl.load(open(output_dir / \"encoder.pkl\", \"rb\"))\n",
    "            selected_y_train_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_train),\n",
    "                index = selected_y_train.index\n",
    "            )\n",
    "            selected_y_test_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_test),\n",
    "                index = selected_y_test.index\n",
    "            )\n",
    "        else:\n",
    "            encoder = LabelEncoder()\n",
    "            selected_y_train_encoded = pd.Series(\n",
    "                encoder.fit_transform(selected_y_train),\n",
    "                index = selected_y_train.index\n",
    "            )\n",
    "            selected_y_test_encoded = pd.Series(\n",
    "                encoder.transform(selected_y_test),\n",
    "                index = selected_y_test.index\n",
    "            )\n",
    "\n",
    "            pkl.dump(encoder, open(output_dir / \"encoder.pkl\", \"wb\"))\n",
    "\n",
    "        MODULE_NAME = \"Classify\"\n",
    "        PROJECT_CODE = \"X24-028\"\n",
    "        MLFLOW_EXPERIMENT_NAME = f\"{MODULE_NAME}_{PROJECT_CODE}_{dataset}_{param}_imba-constrained\"\n",
    "        OPTUNA_STUDY_NAME = f\"{MLFLOW_EXPERIMENT_NAME}_RUN-1_PR70\"\n",
    "        SEED = 42\n",
    "        N_STARTUP_TRIALS = 100\n",
    "        N_TOTAL_TRIALS = 200\n",
    "\n",
    "        sampler = TPESampler(seed=SEED, \n",
    "                            n_startup_trials=N_STARTUP_TRIALS, \n",
    "                            multivariate=True,\n",
    "                            warn_independent_sampling=False)\n",
    "        \n",
    "        objective = CustomObjectiveImbaClassify(\n",
    "            X_train = X_train,\n",
    "            y_train = selected_y_train_encoded,\n",
    "            X_test = X_test,\n",
    "            y_test = selected_y_test_encoded,\n",
    "\n",
    "        )\n",
    "        direction = \"maximize\" # depends on your objective\n",
    "        metric_name = [\"minority_recall\"]\n",
    "\n",
    "        classify_trainer = BaseClassifyTrainerV4(\n",
    "            mlflow_experiment_name = MLFLOW_EXPERIMENT_NAME,\n",
    "            optuna_study_name = OPTUNA_STUDY_NAME,\n",
    "            optuna_storage_url = STORAGE_URL,\n",
    "            sampler = sampler,\n",
    "            n_total_trials = N_TOTAL_TRIALS,\n",
    "            objective = objective,\n",
    "            direction = direction,\n",
    "            metric_name = metric_name,\n",
    "            seed = SEED,\n",
    "            additional_tags = {'metric': metric_name[0]},\n",
    "            enable_checkpointing=True,  # Enable the new feature\n",
    "            sampler_checkpoint_path=None,\n",
    "            encoder = encoder,\n",
    "        )\n",
    "\n",
    "        classify_trainer.run(save_best_model=True)\n",
    "\n",
    "        # pkl.dump(best_model, open(output_dir / \"trainer.pkl\", \"wb\"))\n",
    "        # pkl.dump(chosen_pipeline, open(output_dir / \"origin_model_prediction.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"../models/model.pkl\")\n",
    "\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model = pkl.load(f)\n",
    "\n",
    "model.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "# List all studies in the database\n",
    "optuna.get_all_study_names(storage=STORAGE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download models from mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix_test_lot.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb1786da2e54b2682485b2e9c1b6b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded confusion_matrix_test_lot.png to ..\\models\\cargill\\Acetic-test\n",
      "confusion_matrix_test_mode.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30852d4fbec54872830a765002330fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded confusion_matrix_test_mode.png to ..\\models\\cargill\\Acetic-test\n",
      "confusion_matrix_train.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833e08954ae2473b9cdf08d3040274a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded confusion_matrix_train.png to ..\\models\\cargill\\Acetic-test\n",
      "deployment_pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880145cba8e74d8ab2327ebb3d4ff9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded deployment_pipeline/origin_model_prediction.pkl to ..\\models\\cargill\\Acetic-test\n",
      "model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcfa48550f940de830de444f465da1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/MLmodel to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be04785820124dbd9a6635abe494dd2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/conda.yaml to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dfa0ccb7a44d3d8ac57424d974d072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/metadata/MLmodel to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c8c8f01ab4f16a5196aea298c4356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/metadata/conda.yaml to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f74ea10724ade82b5fd9147062815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/metadata/python_env.yaml to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e511cfa16a184267a9ee673b82a4b25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/metadata/requirements.txt to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e40b8467c144264b2625fcb16ce442c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/model.pkl to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4c43e04f1144e694b850c3d33ac865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/python_env.yaml to ..\\models\\cargill\\Acetic-test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543d1b41517b4c0c8be0f68261418790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model/requirements.txt to ..\\models\\cargill\\Acetic-test\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Get the client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Get the list of all artifacts in the run\n",
    "artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "# Function to recursively download artifacts\n",
    "def download_artifacts(client, run_id, artifact_path, local_dir):\n",
    "    # List all sub-artifacts in the given artifact_path\n",
    "    artifacts = client.list_artifacts(run_id, artifact_path)\n",
    "    \n",
    "    # If it's a directory, recursively download its contents\n",
    "    if len(artifacts) > 0:\n",
    "        for subartifact in artifacts:\n",
    "            # Get the parent directory path and the file name\n",
    "            subartifact_parent_dir, subartifact_file = os.path.split(subartifact.path)\n",
    "            \n",
    "            # Create local directory structure (exclude file name)\n",
    "            subartifact_local_path = os.path.join(local_dir, subartifact_parent_dir)\n",
    "            os.makedirs(subartifact_local_path, exist_ok=True)\n",
    "            \n",
    "            # Recursively download sub-artifacts\n",
    "            download_artifacts(client, run_id, subartifact.path, local_dir)\n",
    "    else:\n",
    "        # If it's a file, ensure the parent directory exists and then download it\n",
    "        local_file_path = local_dir\n",
    "        \n",
    "        # Get the parent directory (exclude file name)\n",
    "        local_dir_path = os.path.dirname(local_file_path)\n",
    "        \n",
    "        # Create the parent directory if it doesn't exist\n",
    "        os.makedirs(local_dir_path, exist_ok=True)\n",
    "        \n",
    "        # Download the file to the correct local path\n",
    "        client.download_artifacts(run_id, artifact_path, dst_path=local_file_path)\n",
    "        print(f\"Downloaded {artifact_path} to {local_file_path}\")\n",
    "\n",
    "\n",
    "# Specify the experiment and run ID\n",
    "experiment_id = \"754667177352290429\"\n",
    "run_id = \"1e7f970f6a8c4d07bea3eca411fb6dbc\"\n",
    "# Specify where you want to download the artifacts locally (this is the root directory)\n",
    "param = \"Acetic\"\n",
    "local_directory = Path (f\"../models/cargill/{param}-test\")\n",
    "\n",
    "# Create the local directory if it doesn't exist\n",
    "os.makedirs(local_directory, exist_ok=True)\n",
    "\n",
    "# List all top-level artifacts in the run\n",
    "artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "# Download all artifacts, including those in directories\n",
    "for artifact in artifacts:\n",
    "    print(artifact.path)\n",
    "    download_artifacts(client, run_id, artifact.path, local_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check deployment pipeline pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;mask&#x27;,\n",
       "                 FeatureMask(mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  Tr...\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True]))),\n",
       "                (&#x27;snv&#x27;, SNV()),\n",
       "                (&#x27;sg&#x27;, SavitzkyGolay(deriv=2, polyorder=2, window=9)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_std=False)),\n",
       "                (&#x27;SVC(RBF)&#x27;,\n",
       "                 SVC(C=844.9517488450753, class_weight=&#x27;balanced&#x27;,\n",
       "                     gamma=1.1486359013100058, probability=True,\n",
       "                     random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;mask&#x27;,\n",
       "                 FeatureMask(mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  Tr...\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True]))),\n",
       "                (&#x27;snv&#x27;, SNV()),\n",
       "                (&#x27;sg&#x27;, SavitzkyGolay(deriv=2, polyorder=2, window=9)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler(with_std=False)),\n",
       "                (&#x27;SVC(RBF)&#x27;,\n",
       "                 SVC(C=844.9517488450753, class_weight=&#x27;balanced&#x27;,\n",
       "                     gamma=1.1486359013100058, probability=True,\n",
       "                     random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureMask</label><div class=\"sk-toggleable__content\"><pre>FeatureMask(mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  T...\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True]))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SNV</label><div class=\"sk-toggleable__content\"><pre>SNV()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SavitzkyGolay</label><div class=\"sk-toggleable__content\"><pre>SavitzkyGolay(deriv=2, polyorder=2, window=9)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler(with_std=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=844.9517488450753, class_weight=&#x27;balanced&#x27;, gamma=1.1486359013100058,\n",
       "    probability=True, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('mask',\n",
       "                 FeatureMask(mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  Tr...\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True]))),\n",
       "                ('snv', SNV()),\n",
       "                ('sg', SavitzkyGolay(deriv=2, polyorder=2, window=9)),\n",
       "                ('scaler', StandardScaler(with_std=False)),\n",
       "                ('SVC(RBF)',\n",
       "                 SVC(C=844.9517488450753, class_weight='balanced',\n",
       "                     gamma=1.1486359013100058, probability=True,\n",
       "                     random_state=42))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploypipeline = pkl.load(open(\"../models/cargill/Ash/deployment_pipeline/origin_model_prediction.pkl\", \"rb\"))\n",
    "deploypipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 620768088714454255, Name: Classify_X24-028_nondeo_Sensory Result_multi_imba\n",
      "Experiment ID: 540546849373847762, Name: Classify_X24-028_nondeo_Sour_multi_imba\n",
      "Experiment ID: 818116591606453438, Name: Classify_X24-028_nondeo_Smoky_multi_imba\n",
      "Experiment ID: 428823008068037852, Name: Classify_X24-028_nondeo_Putrid_multi_imba\n",
      "Experiment ID: 514637445091160990, Name: Classify_X24-028_nondeo_Petroleum (Motor Oil-Rubber)_multi_imba\n",
      "Experiment ID: 896108498091431601, Name: Classify_X24-028_nondeo_Painty (Solvent-Chemical)_multi_imba\n",
      "Experiment ID: 939845810902120851, Name: Classify_X24-028_nondeo_Oxidized (Old Butter-Stale-Cardboard)_multi_imba\n",
      "Experiment ID: 914756838721971246, Name: Classify_X24-028_nondeo_Musty_multi_imba\n",
      "Experiment ID: 234111042273656590, Name: Classify_X24-028_nondeo_Fishy_multi_imba\n",
      "Experiment ID: 411030358396738309, Name: Classify_X24-028_nondeo_Earthy_multi_imba\n",
      "Experiment ID: 877148317299425469, Name: Classify_X24-028_nondeo_Astringent_multi_imba\n",
      "Experiment ID: 204913971469327901, Name: Classify_X24-028_nondeo_Ash_multi_imba\n",
      "Experiment ID: 754667177352290429, Name: Classify_X24-028_nondeo_Acetic_multi_imba\n",
      "Experiment ID: 0, Name: Default\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"Experiment ID: {exp.experiment_id}, Name: {exp.name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classify-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
