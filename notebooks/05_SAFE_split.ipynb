{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required:  \n",
    "    input.csv - preprocessed spectra with 'lot_id' as index (specimen level)  \n",
    "    label.csv - trainable labels with 'lot_id' as index (specimen level)  \n",
    "    meta.csv - metadata containing 'lot_name', 'specimen_id', 'date_scanned', 'analyser_id' (specimen level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 191) (276, 1) (276, 5)\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data/processed\") # change your path as needed\n",
    "\n",
    "train_folder = data_dir / \"train\" # change your path as needed\n",
    "X_train = pd.read_csv(train_folder / \"input.csv\", index_col=0)\n",
    "y_train = pd.read_csv(train_folder / \"label.csv\", index_col=0)\n",
    "meta_train = pd.read_csv(train_folder / \"meta.csv\", index_col=0)\n",
    "\n",
    "assert (X_train.shape[0] == y_train.shape[0]) and (X_train.shape[0] == meta_train.shape[0]), \"Number of rows do not match!\"\n",
    "print(X_train.shape, y_train.shape, meta_train.shape)\n",
    "\n",
    "test_folder = data_dir / \"test\" # change your path as needed\n",
    "X_test = pd.read_csv(test_folder / \"input.csv\", index_col=0)\n",
    "y_test = pd.read_csv(test_folder / \"label.csv\", index_col=0)\n",
    "meta_test = pd.read_csv(test_folder / \"meta.csv\", index_col=0)\n",
    "\n",
    "assert (X_test.shape[0] == y_test.shape[0]) and (X_test.shape[0] == meta_test.shape[0]), \"Number of rows do not match!\"\n",
    "print(X_test.shape, y_test.shape, meta_test.shape)\n",
    "\n",
    "eval_folder = data_dir / \"eval\" # change your path as needed\n",
    "X_eval = pd.read_csv(eval_folder / \"input.csv\", index_col=0)\n",
    "y_eval = pd.read_csv(eval_folder / \"label.csv\", index_col=0)\n",
    "meta_eval = pd.read_csv(eval_folder / \"meta.csv\", index_col=0)\n",
    "\n",
    "assert (X_eval.shape[0] == y_eval.shape[0]) and (X_eval.shape[0] == meta_eval.shape[0]), \"Number of rows do not match!\"\n",
    "print(X_eval.shape, y_eval.shape, meta_eval.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check that samples are sorted by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_all_by_date(X, y, meta):\n",
    "\n",
    "    try:\n",
    "        assert meta['date_scanned'].is_monotonic_increasing, \"samples not sorted by date\"\n",
    "        print(\"Samples already sorted by date.\")\n",
    "        return X, y, meta\n",
    "    except AssertionError:\n",
    "        print(\"Sorting samples by date...\")\n",
    "        pass\n",
    "\n",
    "    X = X.reset_index()\n",
    "    y = y.reset_index()\n",
    "    meta = meta.reset_index()\n",
    "\n",
    "    sorted_indices = meta.sort_values('date_scanned').index\n",
    "    X_sorted = X.loc[sorted_indices]\n",
    "    y_sorted = y.loc[sorted_indices]\n",
    "    meta_sorted = meta.loc[sorted_indices]\n",
    "\n",
    "    X_sorted = X_sorted.set_index('lot_id')\n",
    "    y_sorted = y_sorted.set_index('lot_id')\n",
    "    meta_sorted = meta_sorted.set_index('lot_id')\n",
    "\n",
    "    assert meta_sorted['date_scanned'].is_monotonic_increasing\n",
    "    assert y_sorted.index.equals(meta_sorted.index) and X_sorted.index.equals(meta_sorted.index)\n",
    "\n",
    "    print(\"Samples sorted by date.\")\n",
    "    \n",
    "    return X_sorted, y_sorted, meta_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples already sorted by date.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, meta_train = sort_all_by_date(X_train, y_train, meta_train)\n",
    "X_test, y_test, meta_test = sort_all_by_date(X_test, y_test, meta_test)\n",
    "X_eval, y_eval, meta_eval = sort_all_by_date(X_eval, y_eval, meta_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_disjoint_splits(meta, split_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Split dataset into two disjoint parts based on time\n",
    "    \"\"\"\n",
    "    eval_lot_names = meta['lot_name'].drop_duplicates()\n",
    "    num_lots_total = len(eval_lot_names)\n",
    "    split_point = int(num_lots_total * split_ratio)\n",
    "    \n",
    "    # First part for retrain, second part for retest\n",
    "    train_lot_names = eval_lot_names.iloc[:split_point].values\n",
    "    test_lot_names = eval_lot_names.iloc[split_point:].values\n",
    "\n",
    "    assert set(train_lot_names).isdisjoint(set(test_lot_names)), \"Train and Test lots are not disjoint!\"\n",
    "    \n",
    "    # print(f\"Total lots: {num_lots_total}\")\n",
    "    # print(f\"Retrain lots: {len(train_lot_names)}\")\n",
    "    # print(f\"Retest lots: {len(test_lot_names)}\")\n",
    "    \n",
    "    return train_lot_names, test_lot_names\n",
    "\n",
    "\n",
    "def get_samples_by_lots(X, y, meta, lot_names):\n",
    "    \"\"\"\n",
    "    Extract samples belonging to specified lot names\n",
    "    \"\"\"\n",
    "    X = X.reset_index()\n",
    "    y = y.reset_index()\n",
    "    meta = meta.reset_index()\n",
    "    \n",
    "    indices_to_take = meta[meta['lot_name'].isin(lot_names)].index\n",
    "    \n",
    "    X_taken = X.loc[indices_to_take].set_index('lot_id')\n",
    "    y_taken = y.loc[indices_to_take].set_index('lot_id')\n",
    "    meta_taken = meta.loc[indices_to_take].set_index('lot_id')\n",
    "    \n",
    "    assert X_taken.index.equals(y_taken.index) and X_taken.index.equals(meta_taken.index)\n",
    "    # print(f\"Shapes taken: {X_taken.shape}, {y_taken.shape}, {meta_taken.shape}\")\n",
    "    \n",
    "    return X_taken, y_taken, meta_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (142, 191), (142, 1), (142, 5)\n",
      "test shapes: (66, 191), (66, 1), (66, 5)\n",
      "eval shapes: (68, 191), (68, 1), (68, 5)\n"
     ]
    }
   ],
   "source": [
    "# # create toy data for testing\n",
    "\n",
    "# train_lots_from_train, test_lots_from_train = create_disjoint_splits(meta_train, split_ratio=0.5)\n",
    "\n",
    "# X_test_temp, y_test_temp, meta_test_temp = get_samples_by_lots(\n",
    "#     X_train, y_train, meta_train, test_lots_from_train\n",
    "# )\n",
    "\n",
    "# X_train, y_train, meta_train = get_samples_by_lots(\n",
    "#     X_train, y_train, meta_train, train_lots_from_train\n",
    "# )\n",
    "\n",
    "# test_lots_from_test, eval_lots_from_test = create_disjoint_splits(meta_test_temp, split_ratio=0.5)\n",
    "\n",
    "# X_test, y_test, meta_test = get_samples_by_lots(\n",
    "#     X_test_temp, y_test_temp, meta_test_temp, test_lots_from_test\n",
    "# )\n",
    "\n",
    "# X_eval, y_eval, meta_eval = get_samples_by_lots(\n",
    "#     X_test_temp, y_test_temp, meta_test_temp, eval_lots_from_test\n",
    "# )\n",
    "\n",
    "# print(f\"train shapes: {X_train.shape}, {y_train.shape}, {meta_train.shape}\")\n",
    "# print(f\"test shapes: {X_test.shape}, {y_test.shape}, {meta_test.shape}\")\n",
    "# print(f\"eval shapes: {X_eval.shape}, {y_eval.shape}, {meta_eval.shape}\")\n",
    "\n",
    "# assert set(X_train.index).isdisjoint(set(X_test.index)), \"TRAIN and TEST sets are not disjoint!\"\n",
    "# assert set(X_train.index).isdisjoint(set(X_eval.index)), \"TRAIN and EVAL sets are not disjoint!\"\n",
    "# assert set(X_test.index).isdisjoint(set(X_eval.index)), \"TEST and EVAL  sets are not disjoint!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 SAFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_SAFE_set_disjoint(\n",
    "        X_test, \n",
    "        y_test, \n",
    "        meta_test, \n",
    "        X_eval, \n",
    "        y_eval, \n",
    "        meta_eval,\n",
    "        split_ratio = 0.5\n",
    "        ):\n",
    "    \n",
    "    print(f\"Original shapes of eval set: {X_eval.shape}, {y_eval.shape}, {meta_eval.shape}\")\n",
    "    \n",
    "    # Split test set into two disjoint parts\n",
    "    retrain_lots, retest_lots = create_disjoint_splits(meta_test, split_ratio)\n",
    "\n",
    "    # For SAFE, we want the second part (retest_lots) from test\n",
    "    X_test_taken, y_test_taken, meta_test_taken = get_samples_by_lots(\n",
    "        X_test, y_test, meta_test, retest_lots\n",
    "    )\n",
    "    \n",
    "    # Concatenate to form SAFE eval set\n",
    "    X_SAFE_eval = pd.concat([X_test_taken, X_eval], axis=0)\n",
    "    y_SAFE_eval = pd.concat([y_test_taken, y_eval], axis=0)\n",
    "    meta_SAFE_eval = pd.concat([meta_test_taken, meta_eval], axis=0)\n",
    "\n",
    "    assert X_SAFE_eval.index.equals(y_SAFE_eval.index) and X_SAFE_eval.index.equals(meta_SAFE_eval.index)\n",
    "    print(f\"Shapes of SAFE eval set: {X_SAFE_eval.shape}, {y_SAFE_eval.shape}, {meta_SAFE_eval.shape}\")\n",
    "    \n",
    "    return X_SAFE_eval, y_SAFE_eval, meta_SAFE_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes of eval set: (68, 191), (68, 1), (68, 5)\n",
      "Shapes of SAFE eval set: (102, 191), (102, 1), (102, 5)\n"
     ]
    }
   ],
   "source": [
    "X_SAFE_eval, y_SAFE_eval, meta_SAFE_eval = prepare_SAFE_set_disjoint(\n",
    "    X_test, y_test, meta_test, X_eval, y_eval, meta_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "output_dir = data_dir / \"SAFE_split\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "X_SAFE_eval.to_csv(output_dir / \"input.csv\", index=True)\n",
    "y_SAFE_eval.to_csv(output_dir / \"target.csv\", index=True)\n",
    "meta_SAFE_eval.to_csv(output_dir / \"meta.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_new_train_disjoint(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        meta_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        meta_test,\n",
    "        X_eval,\n",
    "        y_eval,\n",
    "        meta_eval,\n",
    "        ):\n",
    "    \n",
    "    # For retrain, we want all of train set + first half from test + first half from eval\n",
    "\n",
    "    retrain_lots_from_test, _ = create_disjoint_splits(meta_test, split_ratio=0.5)\n",
    "\n",
    "    X_test_taken, y_test_taken, meta_test_taken = get_samples_by_lots(\n",
    "        X_test, y_test, meta_test, retrain_lots_from_test\n",
    "    )\n",
    "    # print(f\"Shapes taken from test set: {X_test_taken.shape}, {y_test_taken.shape}, {meta_test_taken.shape}\")\n",
    "    \n",
    "    retrain_lots_from_eval, _ = create_disjoint_splits(meta_eval, split_ratio=0.5)\n",
    "    X_eval_taken, y_eval_taken, meta_eval_taken = get_samples_by_lots(\n",
    "        X_eval, y_eval, meta_eval, retrain_lots_from_eval\n",
    "    )\n",
    "    \n",
    "    X_retrain = pd.concat([X_train, X_test_taken, X_eval_taken], axis=0)\n",
    "    y_retrain = pd.concat([y_train, y_test_taken, y_eval_taken], axis=0)\n",
    "    meta_retrain = pd.concat([meta_train, meta_test_taken, meta_eval_taken], axis=0)\n",
    "    \n",
    "    assert X_retrain.index.equals(y_retrain.index) and X_retrain.index.equals(meta_retrain.index)\n",
    "    print(f\"Shapes of RETRAIN set: {X_retrain.shape}, {y_retrain.shape}, {meta_retrain.shape}\")\n",
    "    \n",
    "    return X_retrain, y_retrain, meta_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_new_test_disjoint(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        meta_test,\n",
    "        X_eval,\n",
    "        y_eval,\n",
    "        meta_eval\n",
    "        ):\n",
    "    \n",
    "    # For retest, we want all of train set + second half from test + second half from eval\n",
    "\n",
    "    _, retest_lots_from_test = create_disjoint_splits(meta_test, split_ratio=0.5)\n",
    "\n",
    "    X_test_taken, y_test_taken, meta_test_taken = get_samples_by_lots(\n",
    "        X_test, y_test, meta_test, retest_lots_from_test\n",
    "    )\n",
    "    # print(f\"Shapes taken from test set: {X_test_taken.shape}, {y_test_taken.shape}, {meta_test_taken.shape}\")\n",
    "    \n",
    "    _, retest_lots_from_eval = create_disjoint_splits(meta_eval, split_ratio=0.5)\n",
    "\n",
    "    X_eval_taken, y_eval_taken, meta_eval_taken = get_samples_by_lots(\n",
    "        X_eval, y_eval, meta_eval, retest_lots_from_eval\n",
    "    )\n",
    "    \n",
    "    X_retest = pd.concat([X_test_taken, X_eval_taken], axis=0)\n",
    "    y_retest = pd.concat([y_test_taken, y_eval_taken], axis=0)\n",
    "    meta_retest = pd.concat([meta_test_taken, meta_eval_taken], axis=0)\n",
    "    \n",
    "    print(f\"Shapes of RETEST set: {X_retest.shape}, {y_retest.shape}, {meta_retest.shape}\")\n",
    "    \n",
    "    return X_retest, y_retest, meta_retest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original train set: (142, 191), (142, 1), (142, 5)\n",
      "Shape of original test set: (66, 191), (66, 1), (66, 5)\n",
      "Shape of original eval set: (68, 191), (68, 1), (68, 5)\n",
      "\n",
      "\n",
      "Shapes of RETRAIN set: (208, 191), (208, 1), (208, 5)\n",
      "Shapes of RETEST set: (68, 191), (68, 1), (68, 5)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create retrain set using the retrain_lots\n",
    "print(f\"Shape of original train set: {X_train.shape}, {y_train.shape}, {meta_train.shape}\")\n",
    "print(f\"Shape of original test set: {X_test.shape}, {y_test.shape}, {meta_test.shape}\")\n",
    "print(f\"Shape of original eval set: {X_eval.shape}, {y_eval.shape}, {meta_eval.shape}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "X_retrain, y_retrain, meta_retrain = prepare_new_train_disjoint(\n",
    "    X_train, y_train, meta_train,\n",
    "    X_test, y_test, meta_test,\n",
    "    X_eval, y_eval, meta_eval,\n",
    ")\n",
    "\n",
    "# Step 3: Create retest set using the retest_lots  \n",
    "X_retest, y_retest, meta_retest = prepare_new_test_disjoint(\n",
    "    X_test, y_test, meta_test,\n",
    "    X_eval, y_eval, meta_eval\n",
    ")\n",
    "\n",
    "# Verify disjoint property\n",
    "assert set(X_retrain.index).isdisjoint(set(X_retest.index)), \"RETRAIN and RETEST sets are not disjoint!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data\n",
    "output_dir = data_dir / \"retrain\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "X_retrain.to_csv(output_dir / \"input.csv\", index=True)\n",
    "y_retrain.to_csv(output_dir / \"target.csv\", index=True)\n",
    "meta_retrain.to_csv(output_dir / \"meta.csv\", index=True)\n",
    "\n",
    "output_dir = data_dir / \"retest\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "X_retest.to_csv(output_dir / \"input.csv\", index=True)\n",
    "y_retest.to_csv(output_dir / \"target.csv\", index=True)\n",
    "meta_retest.to_csv(output_dir / \"meta.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312pp133",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
